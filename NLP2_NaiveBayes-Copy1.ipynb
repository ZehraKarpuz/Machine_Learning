{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"temp_data3.csv\")\n",
    "df=df.iloc[:4000,:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "list1=df.Sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list1)):\n",
    "    if(list1[i]==\"mixed\"):\n",
    "        df.drop([i],axis=0,inplace=True)\n",
    "    elif(list1[i]==\"neutral\"):\n",
    "        df.drop([i],axis=0,inplace=True)\n",
    "\n",
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa24e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df[\"cleaned_text\"]\n",
    "sentiment=df[\"Sentiment\"]\n",
    "dataf=pd.concat([text,sentiment],axis=1)\n",
    "dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6be850",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataf[\"cleaned_text\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data=data.str.replace(\"[^\\w\\s]\",\"\")#harf dışı simgeler,noktalama\n",
    "data= data.str.replace(\" \\d+\", \" \")#sayılar \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "duraklama_kelimeleri = stopwords.words()\n",
    "data=pd.DataFrame(data,columns=[\"cleaned_text\"])\n",
    "data=data[\"cleaned_text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in duraklama_kelimeleri))\n",
    "data=pd.concat([data,sentiment],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2975c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()#kelime bölümü\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "data['cleaned_text'] = data.cleaned_text.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41724424",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = data['cleaned_text'].values\n",
    "labels = data['Sentiment'].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)\n",
    "#for i in range(len(labels)):\n",
    "    #print(labels[i],\" : \",encoded_labels[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(cleaned_text, encoded_labels, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(train_sentences)#yorumlarda geçen kelimelerin sayısı\n",
    "vocab = vec.get_feature_names()# kelimeler tutulur\n",
    "X = X.toarray()\n",
    "word_counts = {}\n",
    "for l in range(2):# 2 etiket\n",
    "    word_counts[l] = defaultdict(lambda: 0)#sözlük içinde 2 sözlük \n",
    "for i in range(X.shape[0]):\n",
    "    l = train_labels[i]\n",
    "    for j in range(len(vocab)):\n",
    "        word_counts[l][vocab[j]] += X[i][j]#her kelimenin etiketler içindeki sayıları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a9c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6690e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {}\n",
    "def group_by_label(x, y, labels):\n",
    "    for l in labels:\n",
    "        data1[l] = x[np.where(y == l)]# eğitim yorumları etiketlere göre yerleştirilir\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08a88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_label_items = {}\n",
    "log_label_priors = {}\n",
    "def fit(x, y, labels):#egitimyorumları, eg.etikt, etiketler\n",
    "    n = len(x)\n",
    "    grouped_data = group_by_label(x, y, labels)\n",
    "    for l, data in grouped_data.items():#yorumların etiketleri\n",
    "        n_label_items[l] = len(data)# her etikette kaç yorum olduğu tutulur\n",
    "        log_label_priors[l] = math.log(n_label_items[l] / n)# etiketteki yorumsayısı/ eğitim yorumsayısı\n",
    "    return n_label_items, log_label_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6649453",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_label_items, log_label_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e58289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(n_label_items, vocab, word_counts, word,label):\n",
    "    a = word_counts[label][word] + 1 #mevcut etiketteki mevcut kelimenin sayısına eklenir\n",
    "    b = n_label_items[label] + len(vocab)#etiketteki toplam yorum sayısı + kelime sayısı\n",
    "    return math.log(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33619bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "def predict(n_label_items, vocab, word_counts, log_label_priors, labels, test_sentences):\n",
    "    for text in test_sentences:\n",
    "        label_scores = {l: log_label_priors[l] for l in labels}\n",
    "        words = set(w_tokenizer.tokenize(text))\n",
    "        for word in words:\n",
    "            if word not in vocab: continue# eğitim kelimelerindense oranlarda değişiklik olmayacağı için geç\n",
    "            for l in labels:\n",
    "                log_w_given_l = laplace_smoothing(n_label_items, vocab, word_counts, word, l)\n",
    "                label_scores[l] += log_w_given_l# olasılık guncelle\n",
    "        result.append(max(label_scores, key=label_scores.get))#olasılığı en büyük olan etiket\n",
    "    return result#etiket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0,1]\n",
    "n_label_items, log_label_priors = fit(train_sentences,train_labels,labels)\n",
    "pred = predict(n_label_items, vocab, word_counts, log_label_priors, labels, test_sentences)\n",
    "\n",
    "print(\"Accuracy of prediction on test set : \", accuracy_score(test_labels,pred))\n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if(pred[i] == 0):\n",
    "        print(test_sentences[i],\" : negative\\n\")\n",
    "    elif(pred[i] == 1):\n",
    "        print(test_sentences[i],\" : positive\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cb5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
